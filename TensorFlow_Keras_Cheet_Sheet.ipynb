{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard\n",
    "```python\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# set log directory\n",
    "log_directory = 'logs/fit'\n",
    "\n",
    "# add a timestamp if needed\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H%M\")\n",
    "log_directory = log_directory + '/' + timestamp\n",
    "\n",
    "# Set Board\n",
    "board = TensorBoard(log_dir=log_directory,histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1)\n",
    "\n",
    "# While fitting the model, add to callbacks\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop,board])\n",
    "\n",
    "# run this code at command line\n",
    "# make sure you change directory to your notebook\n",
    "tensorboard --logdir logs\\fit \n",
    "```\n",
    "Tensorboard will run locally in your browser at \n",
    "[http://localhost:6006/](http://localhost:6006/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n",
    "```python\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_encoded= to_categorical(y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and Load a Model\n",
    "```python\n",
    "model.save('my_model.h5')  # creates a HDF5 file\n",
    "from tensorflow.keras.models import load_model\n",
    "later_model = load_model('my_model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "\n",
    "```python\n",
    "# Normalizing/Scaling the Data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # we only fit our scaler to the training set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Import Keras Model, Layers, ...\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam',loss='mse') # we can use our imported optimizer or loss function\n",
    "\n",
    "# Train the model\n",
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=400)\n",
    "\n",
    "# Losses\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "# Predictions\n",
    "y_hat = model.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n",
    "\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam') # For Binary Classification\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "model_loss = pd.DataFrame(model.history.history)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graysclae Images 2D\n",
    "\n",
    "```python\n",
    "# First Step\n",
    "Preprocessing the data:\n",
    "    One-Hot Encoding\n",
    "    Scaling\n",
    "    Reshaping\n",
    "    \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation='relu',))\n",
    "# POOLING LAYER\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# FLATTEN IMAGES FROM 28 by 28 to 764 BEFORE FINAL LAYER\n",
    "model.add(Flatten())\n",
    "\n",
    "# 128 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# https://keras.io/metrics/\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']) # we can add in additional metrics https://keras.io/metrics/\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=2)\n",
    "\n",
    "# Train model\n",
    "model.fit(x_train,y_cat_train,epochs=10,validation_data=(x_test,y_cat_test),callbacks=[early_stop])\n",
    "\n",
    "# Evaluate model\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "losses[['accuracy','val_accuracy']].plot()\n",
    "losses[['loss','val_loss']].plot()\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(x_test,y_cat_test,verbose=0))\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "predictions = model.predict_classes(x_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "sns.heatmap(confusion_matrix(y_test,predictions),annot=True)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
